{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flux_mlp_fashionmnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilianabs/benchmarking-dl-frameworks/blob/main/Flux_mlp_fashionmnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> _Colab Notebook Template_\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). This takes a couple of minutes.\n",
        "4. Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeFXS0F0zww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15da30ed-fec5-40c5-870f-ff81a5103bd4"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.7.1\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools Plots Flux MLDatasets\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -n \"$COLAB_GPU\" ] && [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  if [ \"$COLAB_GPU\" = \"1\" ]; then\n",
        "      JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Julia 1.7.1 on the current Colab Runtime...\n",
            "2022-04-05 22:40:19 URL:https://storage.googleapis.com/julialang2/bin/linux/x64/1.7/julia-1.7.1-linux-x86_64.tar.gz [123374573/123374573] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "Installing Julia package BenchmarkTools...\n",
            "Installing Julia package Plots...\n",
            "Installing Julia package Flux...\n",
            "Installing Julia package MLDatasets...\n",
            "Installing Julia package CUDA...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OS3Ac017T1i"
      },
      "source": [
        "# Checking the Installation\n",
        "The `versioninfo()` function should print your Julia version and some other info about the system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzvvzCl1i0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451c1773-e392-41c8-9188-104534d94c38"
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julia Version 1.7.1\n",
            "Commit ac5cc99908 (2021-12-22 19:35 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-pc-linux-gnu)\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-12.0.1 (ORCJIT, haswell)\n",
            "Environment:\n",
            "  JULIA_NUM_THREADS = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using BenchmarkTools\n",
        "\n",
        "M = rand(2^11, 2^11)\n",
        "\n",
        "@btime $M * $M;"
      ],
      "metadata": {
        "id": "YjM_qq54lCcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1367e5-e934-43d0-9248-61b0c457f41e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  478.899 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XciCcMAJOT3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9afac88-7cf4-4494-9bb8-501e906b5c8e"
      },
      "source": [
        "if ENV[\"COLAB_GPU\"] == \"1\"\n",
        "    using CUDA\n",
        "\n",
        "    run(`nvidia-smi`)\n",
        "\n",
        "    # Create a new random matrix directly on the GPU:\n",
        "    M_on_gpu = CUDA.CURAND.rand(2^11, 2^11)\n",
        "    @btime $M_on_gpu * $M_on_gpu; nothing\n",
        "else\n",
        "    println(\"No GPU found.\")\n",
        "end"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr  5 22:50:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "  477.285 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using Flux\n",
        "using Flux.Data: DataLoader\n",
        "using Flux: onehotbatch, onecold, @epochs\n",
        "using Flux.Losses: logitcrossentropy\n",
        "using MLDatasets\n",
        "using Plots\n",
        "using CUDA"
      ],
      "metadata": {
        "id": "67idL7G7lLGY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\""
      ],
      "metadata": {
        "id": "z9ldVj6Ql2NH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb694c9-0743-49d1-bce2-36582378f1e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"true\""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load full training set\n",
        "train_x, train_y = FashionMNIST.traindata(Float32)\n",
        "\n",
        "# load full test set\n",
        "test_x,  test_y  = FashionMNIST.testdata(Float32)"
      ],
      "metadata": {
        "id": "gDx6snNtlUQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87d341b-1c37-47f3-b339-3bf981d04fcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [9, 2, 1, 1, 6, 1, 4, 6, 5, 7  …  5, 6, 8, 9, 1, 9, 1, 8, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size(train_x)"
      ],
      "metadata": {
        "id": "_qFkZv6LlkZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f06398a-ea64-4eb6-c61d-6a07b8ffe812"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size(train_y)"
      ],
      "metadata": {
        "id": "LsIQfN8Muc5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2a9e3a-4ff0-427b-b552-d74da9d1fcbc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique(train_y)"
      ],
      "metadata": {
        "id": "-cjCv93Cl9vV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df6d252-40d5-4cbc-cff1-86639d12d778"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10-element Vector{Int64}:\n",
              " 9\n",
              " 0\n",
              " 3\n",
              " 2\n",
              " 7\n",
              " 5\n",
              " 1\n",
              " 6\n",
              " 4\n",
              " 8"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = Flux.flatten(train_x)\n",
        "test_x = Flux.flatten(test_x)"
      ],
      "metadata": {
        "id": "sYQv5JwOmGsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0382de60-f3ae-4b3d-8c83-015d31dd9965"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784×10000 Matrix{Float32}:\n",
              " 0.0  0.0         0.0         …  0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0         …  0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.00392157     0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.121569  0.0       0.0       0.0\n",
              " 0.0  0.0509804   0.262745    …  0.203922  0.0       0.0       0.0\n",
              " 0.0  0.262745    0.694118       0.384314  0.0       0.643137  0.0\n",
              " 0.0  0.0         0.505882       0.368627  0.0       0.537255  0.0\n",
              " ⋮                            ⋱                                \n",
              " 0.0  0.00784314  0.266667       0.537255  0.470588  0.792157  0.0\n",
              " 0.0  0.00784314  0.690196       0.356863  0.396078  0.054902  0.0\n",
              " 0.0  0.00784314  0.643137       0.0       0.105882  0.0       0.0\n",
              " 0.0  0.0117647   0.227451    …  0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0117647   0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.682353    0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.741176    0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.262745    0.0         …  0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "train_y, test_y = onehotbatch(train_y, 0:9), onehotbatch(test_y, 0:9)"
      ],
      "metadata": {
        "id": "WM42RdqmmO9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54b1c0b-8a4c-4ce0-9183-f269b03f4849"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Bool[0 1 … 1 0; 0 0 … 0 0; … ; 0 0 … 0 0; 1 0 … 0 0], Bool[0 0 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 1 0 … 0 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders (mini-batch iterators)\n",
        "train_data_loader = DataLoader((train_x, train_y), batchsize=64, shuffle=true)\n",
        "test_data_loader = DataLoader((test_x, test_y), batchsize=64)"
      ],
      "metadata": {
        "id": "XVYja3QNuCFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552bdad9-bd5f-4277-830e-df69529c3982"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataLoader{Tuple{Matrix{Float32}, Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}}}, Random._GLOBAL_RNG}((Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 1 0 … 0 0]), 64, 10000, true, 10000, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], false, Random._GLOBAL_RNG())"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA.allowscalar(false)\n",
        "device = gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbpjtHKP81Tv",
        "outputId": "0472608d-23ac-4850-8cbd-69ce42255265"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gpu (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct model\n",
        "img_size = (28,28,1)\n",
        "num_classes = 10\n",
        "\n",
        "model = Chain( Dense(prod(img_size), 512, relu),\n",
        "               Dense(512, 512, relu),\n",
        "               Dense(512, num_classes)) \n",
        "\n",
        "ps = Flux.params(model) # model's trainable parameters\n",
        "\n",
        "# model |> device"
      ],
      "metadata": {
        "id": "3_qU8TBGuOKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc39f9b8-5f54-4863-e1e5-c155f8e9aa27"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Params([Float32[-0.054709226 -0.051337138 … 0.026578406 -0.0023194444; 0.010374862 0.014308265 … 0.0592415 -0.06364672; … ; -0.05236719 0.032355674 … -0.014872518 -0.021380195; 0.019930512 -0.044395424 … 0.017219808 -0.0358684], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.052696817 -0.04587356 … 0.06883099 -0.037374232; -0.010613331 -0.017085772 … 0.017432123 -0.05198341; … ; -0.049667403 -0.017132776 … -0.008835577 -0.03189518; -0.029269582 0.053982846 … 0.03230454 -0.034464203], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.01585538 -0.07165226 … -0.09283537 0.019271884; -0.036619294 -0.05282642 … -0.06798605 -0.095837064; … ; 0.05426361 0.03317631 … -0.001011979 -0.010703018; 0.018936804 0.0585916 … -0.1001359 -0.09097651], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function loss(data_loader, model)\n",
        "    total_loss = 0.0f0\n",
        "    num_elements = 0\n",
        "    for (x, y) in data_loader\n",
        "        ŷ = model(x)\n",
        "        total_loss += logitcrossentropy(ŷ, y, agg=sum)\n",
        "        num_elements +=  size(x)[end]\n",
        "    end\n",
        "    return total_loss / num_elements\n",
        "end\n",
        "\n",
        "\n",
        "function accuracy(data_loader, model)\n",
        "    accuracy = 0\n",
        "    num_elements = 0\n",
        "    for (x, y) in data_loader\n",
        "        ŷ = model(x)\n",
        "        accuracy += sum(onecold(ŷ) .== onecold(y))\n",
        "        num_elements += size(x)[end]\n",
        "    end   \n",
        "    \n",
        "    return accuracy / num_elements\n",
        "end"
      ],
      "metadata": {
        "id": "_G_zvFJ1y2a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b92338-a476-408d-99e9-546fcc492a2c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "accuracy (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "η = 1e-3 \n",
        "\n",
        "opt = Descent(η)"
      ],
      "metadata": {
        "id": "EbMistzKzIDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0813ca-452f-45fb-928d-dc9424908d04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Descent(0.001)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function train()\n",
        "  epochs = 5\n",
        "\n",
        "  train_loss_results = []\n",
        "  test_loss_results = []\n",
        "  train_accuracy_results = []\n",
        "  test_accuracy_results = []\n",
        "\n",
        "  for epoch in 1:epochs\n",
        "      for (x, y) in train_data_loader\n",
        "          gs = gradient(() -> logitcrossentropy(model(x), y), ps) # Compute gradient\n",
        "          Flux.Optimise.update!(opt, ps, gs) # Update parameters\n",
        "      end\n",
        "          \n",
        "      # Compute accuracy and loss for all of the train and test data\n",
        "      train_loss = loss(train_data_loader, model)\n",
        "      train_acc = accuracy(train_data_loader, model)\n",
        "      test_loss = loss(test_data_loader, model)\n",
        "      test_acc = accuracy(test_data_loader, model)\n",
        "      println(\"Epoch=$epoch\")\n",
        "      println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
        "      println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
        "      push!(train_loss_results, train_loss)\n",
        "      push!(test_loss_results, test_loss)\n",
        "      push!(train_accuracy_results, train_acc)\n",
        "      push!(test_accuracy_results, test_acc)\n",
        "  end\n",
        "end"
      ],
      "metadata": {
        "id": "YWTOMAyez3US",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cd1383-1878-42eb-8444-8ff112576fdf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@time train()"
      ],
      "metadata": {
        "id": "z_7hf3Srz-HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad97344-05f8-482b-d7bb-5e574db88eba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=1\n",
            "  train_loss = 0.6431834, train_accuracy = 0.7963666666666667\n",
            "  test_loss = 0.6614916, test_accuracy = 0.7831\n",
            "Epoch=2\n",
            "  train_loss = 0.61620647, train_accuracy = 0.8061\n",
            "  test_loss = 0.63583106, test_accuracy = 0.7905\n",
            "Epoch=3\n",
            "  train_loss = 0.59294116, train_accuracy = 0.8119166666666666\n",
            "  test_loss = 0.6130389, test_accuracy = 0.7982\n",
            "Epoch=4\n",
            "  train_loss = 0.57469404, train_accuracy = 0.8159\n",
            "  test_loss = 0.5951256, test_accuracy = 0.8018\n",
            "Epoch=5\n",
            "  train_loss = 0.5588081, train_accuracy = 0.8203333333333334\n",
            "  test_loss = 0.5801001, test_accuracy = 0.8079\n",
            " 72.188560 seconds (2.32 M allocations: 26.898 GiB, 4.88% gc time, 0.29% compilation time)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u6X5xR_c8E-r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}