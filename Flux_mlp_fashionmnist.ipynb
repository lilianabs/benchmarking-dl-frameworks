{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flux_mlp_fashionmnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilianabs/benchmarking-dl-frameworks/blob/main/Flux_mlp_fashionmnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> _Colab Notebook Template_\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). This takes a couple of minutes.\n",
        "4. Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeFXS0F0zww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74be4fb8-0cc6-414e-f0ad-31de1499d815"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.7.1\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools Plots Flux MLDatasets\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -n \"$COLAB_GPU\" ] && [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  if [ \"$COLAB_GPU\" = \"1\" ]; then\n",
        "      JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Julia 1.7.1 on the current Colab Runtime...\n",
            "2022-04-04 21:46:19 URL:https://julialang-s3.julialang.org/bin/linux/x64/1.7/julia-1.7.1-linux-x86_64.tar.gz [123374573/123374573] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "Installing Julia package BenchmarkTools...\n",
            "Installing Julia package Plots...\n",
            "Installing Julia package Flux...\n",
            "Installing Julia package MLDatasets...\n",
            "Installing Julia package CUDA...\n",
            "Installing IJulia kernel...\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mInstalling julia kernelspec in /root/.local/share/jupyter/kernels/julia-1.7\n",
            "\n",
            "Successfully installed julia version 1.7.1!\n",
            "Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\n",
            "jump to the 'Checking the Installation' section.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OS3Ac017T1i"
      },
      "source": [
        "# Checking the Installation\n",
        "The `versioninfo()` function should print your Julia version and some other info about the system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzvvzCl1i0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08a37d7-4909-4906-9f92-86e018537310"
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julia Version 1.7.1\n",
            "Commit ac5cc99908 (2021-12-22 19:35 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-pc-linux-gnu)\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-12.0.1 (ORCJIT, haswell)\n",
            "Environment:\n",
            "  JULIA_NUM_THREADS = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using BenchmarkTools\n",
        "\n",
        "M = rand(2^11, 2^11)\n",
        "\n",
        "@btime $M * $M;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjM_qq54lCcs",
        "outputId": "378452f8-917d-4207-ad9f-132b0a67ff02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  480.543 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XciCcMAJOT3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d99a91-87d5-45be-a1d4-d58a06e24a82"
      },
      "source": [
        "if ENV[\"COLAB_GPU\"] == \"1\"\n",
        "    using CUDA\n",
        "\n",
        "    run(`nvidia-smi`)\n",
        "\n",
        "    # Create a new random matrix directly on the GPU:\n",
        "    M_on_gpu = CUDA.CURAND.rand(2^11, 2^11)\n",
        "    @btime $M_on_gpu * $M_on_gpu; nothing\n",
        "else\n",
        "    println(\"No GPU found.\")\n",
        "end"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr  4 21:56:58 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "  483.107 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using Flux\n",
        "using Flux.Data: DataLoader\n",
        "using Flux: onehotbatch, onecold, @epochs\n",
        "using Flux.Losses: logitcrossentropy\n",
        "using MLDatasets\n",
        "using Plots"
      ],
      "metadata": {
        "id": "67idL7G7lLGY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9ldVj6Ql2NH",
        "outputId": "0215c082-82b7-4a66-b01b-f99b20956731"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"true\""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load full training set\n",
        "train_x, train_y = FashionMNIST.traindata(Float32)\n",
        "\n",
        "# load full test set\n",
        "test_x,  test_y  = FashionMNIST.testdata(Float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDx6snNtlUQe",
        "outputId": "940a33da-f1d1-42dc-f0e5-b7682dbb9338"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [9, 2, 1, 1, 6, 1, 4, 6, 5, 7  …  5, 6, 8, 9, 1, 9, 1, 8, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size(train_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qFkZv6LlkZ2",
        "outputId": "a840a0a3-5f34-47b9-bd04-d25e30706dbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cjCv93Cl9vV",
        "outputId": "486755b8-02ce-48f4-f68f-c8c0927093f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = Flux.flatten(train_x)\n",
        "test_x = Flux.flatten(test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYQv5JwOmGsL",
        "outputId": "d60871a0-9edc-43ab-a33a-2d94a9438239"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784×10000 Matrix{Float32}:\n",
              " 0.0  0.0         0.0         …  0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0         …  0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.00392157     0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.121569  0.0       0.0       0.0\n",
              " 0.0  0.0509804   0.262745    …  0.203922  0.0       0.0       0.0\n",
              " 0.0  0.262745    0.694118       0.384314  0.0       0.643137  0.0\n",
              " 0.0  0.0         0.505882       0.368627  0.0       0.537255  0.0\n",
              " ⋮                            ⋱                                \n",
              " 0.0  0.00784314  0.266667       0.537255  0.470588  0.792157  0.0\n",
              " 0.0  0.00784314  0.690196       0.356863  0.396078  0.054902  0.0\n",
              " 0.0  0.00784314  0.643137       0.0       0.105882  0.0       0.0\n",
              " 0.0  0.0117647   0.227451    …  0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0117647   0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.682353    0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.741176    0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.262745    0.0         …  0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0\n",
              " 0.0  0.0         0.0            0.0       0.0       0.0       0.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WM42RdqmmO9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}